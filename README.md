# Teleoperation-of-Robotic-Arm-Using-Leap-motion-and-Webcam
## Abstract
The field of robotics has undergone tremendous advancement in recent times. Today, robots are not only expected to be precise and durable but their capabilities are expected to resemble those of humans as closely as possible. In our project, we plan to implement a novel and intuitive human-robot interaction system based on a Leap Motion sensor and a robotic arm. Leap Motion is an example of groundbreaking technology that has the potential to change the way we control machines and therefore, how we control our world! Leap Motion is a sensor that is currently used to navigate through a personal computer with just hand gestures. The Leap Motion sensor will capture human hand gestures and will translate them into movement of the robotic arm. Also, computer vision will be employed to enable intelligent recognition of objects in the sensor’s view. This will enable a more natural human-robot interaction of the robotic arm and will also ensure smooth and efficient manipulation. Hence, our study will discuss and demonstrate how a human can interact with a robot through simple hand gestures. We intend to build a working prototype of the system by the end of the project. We also plan to use Webcam to capture the location or motion of objects by image processing and manipulate the arm to grasp objects. The robot could be used for virtually any application, including research or service in the medical or military fields.

## Problem Statement
- A. System Description
The system consists of the hand tracking device (Leap Motion controller) and a robot with dual arms. Hand tracking is done with Leap motion device and processing software will be used to retrieve the position data from the tracking sensor. The hand (finger) position data will be translated into joint angles by inverse kinematics (mapping algorithm). The robot arm will be operated by the known joint angles in real-time. We are yet to finalize the robot, however, we have shortlisted a few and will be taking the decision on the robot soon.
- B. System principle
Many software are capable of interfacing the Leap motion with a PC, e.g. Node, Processing. In our project, the software will be used to extract skeleton data of hand which will then be analyzed and filtered using computer vision/object recognition algorithms and classifiers. The filtered data will be fed into the movement algorithms to calculate the each joint angle. The structure and the flow of the system are shown in the block diagram.
- C. Leap Motion Controller
The Leap Motion sensor is an advanced motion sensor that will be used to capture the movement of the human hand. It uses a combination of two cameras and three infrared LEDs to observe an area roughly the shape of a hemisphere with a radius of 1 meter. The LEDs generate pattern-less IR light and the cameras generate almost 300 frames per second of reflected data, which is then sent through a USB cable to the host computer. The sensors are directed along the y-axis – upward when the controller is in its standard operating position – and have a field of view of about 150 degrees. The effective range of the Leap Motion Controller extends from approximately 25 to 600 millimeters above the device (1 inch to 2 feet). There, it is analyzed by the Leap Motion controller software using mathematical algorithms to synthesize 3D position data by comparing the 2D frames generated by the two cameras.
The Leap Motion system employs a right-handed Cartesian coordinate system. The origin is centered at the top of the Leap Motion Controller. The x- and z-axes lie in the horizontal plane, with the x-axis running parallel to the long edge of the device. The y-axis is vertical, with positive values increasing upwards (in contrast to the downward orientation of most computer graphics coordinate systems). The z-axis has positive values increasing toward the user. The Leap Motion sensor’s field of view is an inverted pyramid, limiting the range of motion more as the hand approaches the sensor. As the hand rises, the wider the range of motion becomes. The field view is of 150 degrees and can sense from 25 mm to 600mm directly above the device. The red box shown in figure 2.8, is called the interaction box. As long as the hand remains within that box, Leap Motion will be able to accurately read detect its position. The user can also scale the coordinate system to make the device more or less sensitive, depending on the chosen application. 
- D. uArm
uArm is a 4-axis parallel-mechanism robot arm and is made up of laser cut acrylic parts, powered by standard RC hobby servos, and controlled by an Arduino-compatible board. In parallel-mechanism robot arms, most of the masses concentrate on the base, making the robot much more stable and allows the upper Arm to react speedily. 
## Result
- 
